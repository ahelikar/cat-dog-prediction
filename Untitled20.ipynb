{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAXs_rDST2GX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BFQhvCLalmwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "8O0RLVt1bPYX",
        "outputId": "e703b058-552d-41f5-a004-50c1735b8df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-27d2d1a6-5ce0-49be-b8c0-82c782c0eba3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-27d2d1a6-5ce0-49be-b8c0-82c782c0eba3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle (1).json': b'{\"username\":\"ahelikar\",\"key\":\"8721413deebd6f298736b03cb2e0fe53\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Ddo4Oh5RbsP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d tongpython/cat-and-dog"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH7-hDyMbxG-",
        "outputId": "bddd7d93-1496-4fb2-9234-85965a05c006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/tongpython/cat-and-dog\n",
            "License(s): CC0-1.0\n",
            "cat-and-dog.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Gk61n8yajBzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip cat-and-dog.zip -d pet"
      ],
      "metadata": {
        "id": "5Q117A5EcQ6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir=Path('/content/pet/training_set/training_set')\n",
        "test_dir=Path('/content/pet/test_set/test_set')"
      ],
      "metadata": {
        "id": "QxPom39igdjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c64e2ed2",
        "outputId": "bc66ef7f-9744-4aae-e25e-7c508e5a2a89"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Recreate image_df\n",
        "# Note: image_dir currently points to a corrupted zip file, so this dataframe will likely be empty.\n",
        "filepaths_train = list(train_dir.glob(r'**/*.jpg'))\n",
        "labels_train = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths_train))\n",
        "\n",
        "filepaths_series_train = pd.Series(filepaths_train, name='Filepath').astype(str)\n",
        "labels_series_train = pd.Series(labels_train, name='Label')\n",
        "\n",
        "image_df = pd.concat([filepaths_series_train, labels_series_train], axis=1)\n",
        "\n",
        "# Recreate test_image_df\n",
        "filepaths_test = list(test_dir.glob(r'**/*.jpg'))\n",
        "labels_test = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths_test))\n",
        "\n",
        "filepaths_series_test = pd.Series(filepaths_test, name='Filepath').astype(str)\n",
        "labels_series_test = pd.Series(labels_test, name='Label')\n",
        "\n",
        "test_image_df = pd.concat([filepaths_series_test, labels_series_test], axis=1)\n",
        "\n",
        "print(\"image_df:\")\n",
        "print(image_df.head())\n",
        "print(\"\\ntest_image_df:\")\n",
        "print(test_image_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image_df:\n",
            "Empty DataFrame\n",
            "Columns: [Filepath, Label]\n",
            "Index: []\n",
            "\n",
            "test_image_df:\n",
            "Empty DataFrame\n",
            "Columns: [Filepath, Label]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_df = test_image_df.dropna(subset=['Filepath'])\n"
      ],
      "metadata": {
        "id": "YcAsOthTaac5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Activation,Dropout,Flatten,Dense\n",
        "model=Sequential()\n",
        "model.add(Conv2D(32,(3,3),input_shape=(224,224,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(32,(3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(64,(3,3)))\n",
        "model.add(Flatten()) # Added Flatten layer\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                 optimizer='adam',\n",
        "                 metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fel9eovoacOZ",
        "outputId": "8a4a56c3-f599-4068-c4d7-751c78718d4e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
        "                                                               horizontal_flip=True,\n",
        "                                                               width_shift_range=0.2,\n",
        "                                                               height_shift_range=0.2,\n",
        "                                                               validation_split=0.2)\n",
        "test_generator=tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n"
      ],
      "metadata": {
        "id": "P3KTP5lgautI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_images=train_generator.flow_from_dataframe(\n",
        "    dataframe=image_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224,224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "val_images=train_generator.flow_from_dataframe(\n",
        "        dataframe=image_df,\n",
        "\n",
        "    x_col='Filepath',\n",
        "\n",
        "    y_col='Label',\n",
        "\n",
        "    target_size=(224,224),\n",
        "\n",
        "    color_mode='rgb',\n",
        "\n",
        "    class_mode='categorical', # Changed from 'binary' to 'categorical'\n",
        "\n",
        "    batch_size=32,\n",
        "\n",
        "    shuffle=True,\n",
        "\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "if test_image_df.empty:\n",
        "    raise ValueError(\"test_image_df is empty. Please check the test image paths and ensure files exist in: \" + str(test_image_dir))\n",
        "\n",
        "test_images = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_image_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AXFQtBua1zj",
        "outputId": "8f2b76cc-8c69-4c30-e2f6-9708ee14a728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8005 validated image filenames belonging to 2 classes.\n",
            "Found 8005 validated image filenames belonging to 2 classes.\n",
            "Found 2023 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_images,\n",
        "          steps_per_epoch=len(train_images),\n",
        "          epochs=10,\n",
        "          validation_data=val_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9V0VSt2g9om",
        "outputId": "b9273e5c-02a1-4a36-9811-75b4febd1ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 743ms/step - accuracy: 0.4997 - loss: 0.6929 - val_accuracy: 0.5002 - val_loss: 0.6932\n",
            "Epoch 2/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 734ms/step - accuracy: 0.4994 - loss: 0.6932 - val_accuracy: 0.5003 - val_loss: 0.6931\n",
            "Epoch 3/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 731ms/step - accuracy: 0.4995 - loss: 0.6932 - val_accuracy: 0.5003 - val_loss: 0.6931\n",
            "Epoch 4/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 735ms/step - accuracy: 0.4976 - loss: 0.6932 - val_accuracy: 0.5003 - val_loss: 0.6931\n",
            "Epoch 5/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 736ms/step - accuracy: 0.4846 - loss: 0.6932 - val_accuracy: 0.5004 - val_loss: 0.6931\n",
            "Epoch 6/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 733ms/step - accuracy: 0.4932 - loss: 0.6932 - val_accuracy: 0.4997 - val_loss: 0.6932\n",
            "Epoch 7/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 737ms/step - accuracy: 0.5003 - loss: 0.6932 - val_accuracy: 0.5460 - val_loss: 0.6902\n",
            "Epoch 8/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 741ms/step - accuracy: 0.5045 - loss: 0.7087 - val_accuracy: 0.5003 - val_loss: 0.6932\n",
            "Epoch 9/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 736ms/step - accuracy: 0.5065 - loss: 0.6931 - val_accuracy: 0.4997 - val_loss: 0.6932\n",
            "Epoch 10/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 745ms/step - accuracy: 0.5071 - loss: 0.6931 - val_accuracy: 0.5003 - val_loss: 0.6932\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x786c383d0b30>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('pet.weights.h5')"
      ],
      "metadata": {
        "id": "JR44ipWTra11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# 1. RE-CREATE THE EXACT SAME ARCHITECTURE\n",
        "# This must be identical to the model you used to save 'pet.weights.h5'\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax') # Must match the number of classes\n",
        "])\n",
        "model.load_weights('pet.weights.h5')\n",
        "\n",
        "print(\"Model weights loaded successfully!\")\n",
        "\n",
        "# 3. COMPILE (Required before you can predict or evaluate)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujz8DEgJBwwf",
        "outputId": "750e91c4-2fdf-43f4-9985-381f70a5149f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images=train_generator.flow_from_dataframe(\n",
        "    dataframe=image_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224,224),\n",
        "    color_mode='rgb',\n",
        "    class_mode=None,\n",
        "    batch_size=16,\n",
        "    shuffle=False\n",
        ")\n",
        "bottleneck_features_train=model.predict(train_images,2000)\n",
        "np.save(open('bottleneck_features_train.npy', 'w'), bottleneck_features_train)\n",
        "\n",
        "train_images = datagen.flow_from_directory(\n",
        "            dataframe=image_df,\n",
        "            x_col='Filepath',\n",
        "            y_col='Label',\n",
        "\n",
        "        target_size=(150, 150),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None,\n",
        "        shuffle=False)\n",
        "bottleneck_features_validation = model.predict_generator(generator, 800)\n",
        "np.save(open('bottleneck_features_validation.npy', 'w'), bottleneck_features_validation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "FJL0r0u9EMMj",
        "outputId": "3a8a5da6-fe52-4fb0-e51c-bedcedfc2ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Filepath'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Filepath'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2304372677.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_images=train_generator.flow_from_dataframe(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdataframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Filepath'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_dataframe\u001b[0;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m             )\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m         return DataFrameIterator(\n\u001b[0m\u001b[1;32m   1209\u001b[0m             \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, keep_aspect_ratio, dtype, validate_filenames)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclass_mode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multi_output\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweight_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mweight_col\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Filepath'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import optimizers\n",
        "import numpy as np\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# 2. BUILD THE TOP MODEL (The Classifier)\n",
        "# This model will be trained to recognize Cats vs Dogs\n",
        "top_model = Sequential([\n",
        "    Flatten(input_shape=base_model.output_shape[1:]),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax') # 2 classes: Cats and Dogs\n",
        "])\n",
        "\n",
        "# NOTE: Do NOT call top_model.load_weights('pet.weights.h5') here.\n",
        "# Those weights belong to your OLD CNN. You need to train THIS new model first.\n",
        "\n",
        "# NOTE: Do NOT call top_model.load_weights('pet.weights.h5') here.\n",
        "# Those weights belong to your OLD CNN. You need to train THIS new model first.\n",
        "\n",
        "full_input = Input(shape=(224, 224, 3))\n",
        "x = base_model(full_input)\n",
        "full_output = top_model(x)\n",
        "model = Model(inputs=full_input, outputs=full_output)\n",
        "\n",
        "# 4. FREEZE VGG16 LAYERS\n",
        "# We don't want to ruin the pre-trained VGG16 weights during initial training\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 5. COMPILE\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "np.save('bottleneck_features_train.npy', bottleneck_features_train)\n",
        "\n",
        "\n",
        "print(\"Model is ready for training. The architecture mismatch is resolved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "CpuXeXF9DsE1",
        "outputId": "3d05a33f-f561-4a41-ed6e-83865cad2de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'bottleneck_features_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1530356778.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bottleneck_features_train.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottleneck_features_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'bottleneck_features_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfd15f5f"
      },
      "source": [
        "# Task\n",
        "Verify the unzipped dataset structure and correct the `train_dir` and `test_dir` paths in cell `QxPom39igdjF` to `/content/pet/dataset/training_set` and `/content/pet/dataset/test_set`, respectively. Then, re-run cell `c64e2ed2` to populate the `image_df` and `test_image_df` dataframes. Finally, fix cell `FJL0r0u9EMMj` by updating the `model.predict` calls, ensuring all necessary variables (like `datagen`, `batch_size`, `generator`) are defined and correctly used, and saving the bottleneck features using `np.save` with binary write mode (`'wb'`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "160bf297"
      },
      "source": [
        "## Verify Dataset Extraction\n",
        "\n",
        "### Subtask:\n",
        "Check if the `cat-and-dog` dataset has been correctly unzipped and the `/content/pet` directory exists with the expected subdirectories (e.g., `training_set`, `test_set`). This involves listing the contents of `/content` and `/content/pet`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e646465"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires verifying the dataset extraction by listing the contents of the `/content` directory to confirm the presence of the `pet` directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c5ec3ec",
        "outputId": "de35eee4-6416-4ac5-b46b-55c2660c14b4"
      },
      "source": [
        "print('Listing contents of /content:')\n",
        "!ls -F /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing contents of /content:\n",
            "pet.weights.h5\tsample_data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02067598"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous step listed the contents of `/content`. Now, as per the subtask instructions, I need to list the contents of the `/content/pet` directory to verify its structure after unzipping.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ba0fe42",
        "outputId": "7afc8709-0e74-420e-f1bc-e597f5bfffa5"
      },
      "source": [
        "print('Listing contents of /content/pet:')\n",
        "!ls -F /content/pet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing contents of /content/pet:\n",
            "ls: cannot access '/content/pet': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8d3ed6e"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to list the contents of `/content/pet` failed because the directory does not exist. This indicates that the `unzip` command in cell `5Q117A5EcQ6Q` was not executed or failed. To rectify this and allow the subtask to verify the unzipped dataset structure, I will re-execute the `unzip` command to ensure the dataset is extracted into the `/content/pet` directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8160cae0",
        "outputId": "14ad50ae-28f3-4d34-f47a-6793fb6fa7b4"
      },
      "source": [
        "!unzip cat-and-dog.zip -d pet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open cat-and-dog.zip, cat-and-dog.zip.zip or cat-and-dog.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "075db3ce"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous `unzip` command failed because `cat-and-dog.zip` could not be found. Although Kaggle reported 'Skipping' the download earlier, it seems the file is not currently in the working directory. To ensure the zip file is present for unzipping, I will force the download of the `cat-and-dog` dataset using the `--force` flag.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7110d06a",
        "outputId": "840da717-c6d0-4fee-c737-663ff68da890"
      },
      "source": [
        "print('Forcing download of cat-and-dog dataset:')\n",
        "!kaggle datasets download -d tongpython/cat-and-dog --force"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forcing download of cat-and-dog dataset:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/cli.py\", line 68, in main\n",
            "    out = args.func(**command_args)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1741, in dataset_download_cli\n",
            "    with self.build_kaggle_client() as kaggle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
            "    username=self.config_values['username'],\n",
            "             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'username'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2f55faf"
      },
      "source": [
        "**Reasoning**:\n",
        "The `KeyError: 'username'` indicates that the Kaggle API key is not correctly configured. The output from cell `8O0RLVt1bPYX` shows that the uploaded file was saved as `kaggle (1).json`. The current Kaggle setup command in cell `Ddo4Oh5RbsP5` attempts to copy `kaggle.json`. To fix this, I need to update the `cp` command to use the correct filename `kaggle (1).json` to ensure the API key is properly placed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b14758cf",
        "outputId": "4ca21bd8-14df-4763-f148-281b1866e057"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp 'kaggle (1).json' ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle (1).json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aee93fc"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to copy `kaggle (1).json` failed with 'cannot stat'. This implies the file might not be present in the current directory, or its name might have been altered. I will list the contents of the current directory to confirm the exact filename of the Kaggle API key file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39674544",
        "outputId": "60ae74dc-a4b1-4e44-d553-c5fae66f675f"
      },
      "source": [
        "print('Listing files in current directory:')\n",
        "!ls -F"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing files in current directory:\n",
            "pet.weights.h5\tsample_data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6076dde4"
      },
      "source": [
        "train_dir=Path('/content/pet/training_set/training_set')\n",
        "test_dir=Path('/content/pet/test_set/test_set')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78c378f3",
        "outputId": "505461c9-5880-4c85-929e-6dec40266293"
      },
      "source": [
        "import numpy as np\n",
        "# Assuming base_model (VGG16 without top) is already defined from cell Ujz8DEgJBwwf or CpuXeXF9DsE1\n",
        "# Assuming train_generator and test_generator are defined from cell P3KTP5lgautI\n",
        "# Assuming image_df and test_image_df are populated from cell c304ff87 or c304ff87\n",
        "\n",
        "batch_size = 32 # Define batch_size\n",
        "\n",
        "# 1. Generate bottleneck features for the training data\n",
        "print(\"Generating bottleneck features for training data...\")\n",
        "train_bottleneck_generator = train_generator.flow_from_dataframe(\n",
        "    dataframe=image_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode=None,  # No labels needed for feature extraction\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,    # Important to keep order for later matching with labels\n",
        "    subset='training' # Use the training split from train_generator's validation_split\n",
        ")\n",
        "# Use base_model to get features before the custom top layers\n",
        "bottleneck_features_train = base_model.predict(train_bottleneck_generator, steps=len(train_bottleneck_generator), verbose=1)\n",
        "np.save(open('bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
        "print(f\"Shape of bottleneck_features_train: {bottleneck_features_train.shape}\")\n",
        "print(\"Bottleneck features for training data saved to bottleneck_features_train.npy\")\n",
        "\n",
        "\n",
        "# 2. Generate bottleneck features for the validation data\n",
        "print(\"\\nGenerating bottleneck features for validation data...\")\n",
        "validation_bottleneck_generator = train_generator.flow_from_dataframe(\n",
        "    dataframe=image_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode=None,  # No labels needed for feature extraction\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,    # Important to keep order\n",
        "    subset='validation' # Use the validation split from train_generator's validation_split\n",
        ")\n",
        "# Use base_model to get features before the custom top layers\n",
        "bottleneck_features_validation = base_model.predict(validation_bottleneck_generator, steps=len(validation_bottleneck_generator), verbose=1)\n",
        "np.save(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)\n",
        "print(f\"Shape of bottleneck_features_validation: {bottleneck_features_validation.shape}\")\n",
        "print(\"Bottleneck features for validation data saved to bottleneck_features_validation.npy\")\n",
        "\n",
        "\n",
        "# 3. Generate bottleneck features for the test data\n",
        "print(\"\\nGenerating bottleneck features for test data...\")\n",
        "test_bottleneck_generator = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_image_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode=None, # No labels needed\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "# Use base_model to get features before the custom top layers\n",
        "bottleneck_features_test = base_model.predict(test_bottleneck_generator, steps=len(test_bottleneck_generator), verbose=1)\n",
        "np.save(open('bottleneck_features_test.npy', 'wb'), bottleneck_features_test)\n",
        "print(f\"Shape of bottleneck_features_test: {bottleneck_features_test.shape}\")\n",
        "print(\"Bottleneck features for test data saved to bottleneck_features_test.npy\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating bottleneck features for training data...\n",
            "Found 6404 validated image filenames.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 435ms/step\n",
            "Shape of bottleneck_features_train: (6404, 7, 7, 512)\n",
            "Bottleneck features for training data saved to bottleneck_features_train.npy\n",
            "\n",
            "Generating bottleneck features for validation data...\n",
            "Found 1601 validated image filenames.\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 458ms/step\n",
            "Shape of bottleneck_features_validation: (1601, 7, 7, 512)\n",
            "Bottleneck features for validation data saved to bottleneck_features_validation.npy\n",
            "\n",
            "Generating bottleneck features for test data...\n",
            "Found 2023 validated image filenames.\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 222ms/step\n",
            "Shape of bottleneck_features_test: (2023, 7, 7, 512)\n",
            "Bottleneck features for test data saved to bottleneck_features_test.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c3c6ad2",
        "outputId": "0263b988-7180-47b7-abb7-2854e7aaf64f"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "# Assuming base_model (VGG16 without top) is already defined from cell Ujz8DEgJBwwf or CpuXeXF9DsE1\n",
        "# Assuming train_generator and test_generator are defined from cell P3KTP5lgautI\n",
        "# Assuming image_df and test_image_df are populated from cell c304ff87 or c304ff87\n",
        "\n",
        "batch_size = 32 # Define batch_size\n",
        "\n",
        "# 1. Generate bottleneck features for the training data\n",
        "print(\"Generating bottleneck features for training data...\")\n",
        "train_bottleneck_generator = train_generator.flow_from_dataframe(\n",
        "    dataframe=image_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode=None,  # No labels needed for feature extraction\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,    # Important to keep order for later matching with labels\n",
        "    subset='training',\n",
        "    workers=os.cpu_count(),\n",
        "    use_multiprocessing=True\n",
        ")\n",
        "# Use base_model to get features before the custom top layers\n",
        "bottleneck_features_train = base_model.predict(train_bottleneck_generator, steps=len(train_bottleneck_generator), verbose=1)\n",
        "np.save(open('bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
        "print(f\"Shape of bottleneck_features_train: {bottleneck_features_train.shape}\")\n",
        "print(\"Bottleneck features for training data saved to bottleneck_features_train.npy\")\n",
        "\n",
        "\n",
        "# 2. Generate bottleneck features for the validation data\n",
        "print(\"\\nGenerating bottleneck features for validation data...\")\n",
        "validation_bottleneck_generator = train_generator.flow_from_dataframe(\n",
        "    dataframe=image_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode=None,  # No labels needed for feature extraction\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,    # Important to keep order\n",
        "    subset='validation',\n",
        "    workers=os.cpu_count(),\n",
        "    use_multiprocessing=True\n",
        ")\n",
        "# Use base_model to get features before the custom top layers\n",
        "bottleneck_features_validation = base_model.predict(validation_bottleneck_generator, steps=len(validation_bottleneck_generator), verbose=1)\n",
        "np.save(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)\n",
        "print(f\"Shape of bottleneck_features_validation: {bottleneck_features_validation.shape}\")\n",
        "print(\"Bottleneck features for validation data saved to bottleneck_features_validation.npy\")\n",
        "\n",
        "\n",
        "# 3. Generate bottleneck features for the test data\n",
        "print(\"\\nGenerating bottleneck features for test data...\")\n",
        "test_bottleneck_generator = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_image_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode=None, # No labels needed\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    workers=os.cpu_count(),\n",
        "    use_multiprocessing=True\n",
        ")\n",
        "# Use base_model to get features before the custom top layers\n",
        "bottleneck_features_test = base_model.predict(test_bottleneck_generator, steps=len(test_bottleneck_generator), verbose=1)\n",
        "np.save(open('bottleneck_features_test.npy', 'wb'), bottleneck_features_test)\n",
        "print(f\"Shape of bottleneck_features_test: {bottleneck_features_test.shape}\")\n",
        "print(\"Bottleneck features for test data saved to bottleneck_features_test.npy\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating bottleneck features for training data...\n",
            "Found 6404 validated image filenames.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 425ms/step\n",
            "Shape of bottleneck_features_train: (6404, 7, 7, 512)\n",
            "Bottleneck features for training data saved to bottleneck_features_train.npy\n",
            "\n",
            "Generating bottleneck features for validation data...\n",
            "Found 1601 validated image filenames.\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 415ms/step\n",
            "Shape of bottleneck_features_validation: (1601, 7, 7, 512)\n",
            "Bottleneck features for validation data saved to bottleneck_features_validation.npy\n",
            "\n",
            "Generating bottleneck features for test data...\n",
            "Found 2023 validated image filenames.\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 172ms/step\n",
            "Shape of bottleneck_features_test: (2023, 7, 7, 512)\n",
            "Bottleneck features for test data saved to bottleneck_features_test.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0d4f190",
        "outputId": "b7c0a270-b6b1-4fa4-b47a-420731885394"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "# Assuming base_model (VGG16 without top) is already defined from cell Ujz8DEgJBwwf or CpuXeXF9DsE1\n",
        "# Assuming train_generator and test_generator are defined from cell P3KTP5lgautI\n",
        "# Assuming image_df and test_image_df are populated from cell c304ff87 or c304ff87\n",
        "\n",
        "batch_size = 32 # Define batch_size\n",
        "\n",
        "# 1. Generate bottleneck features for the training data\n",
        "print(\"Generating bottleneck features for training data...\")\n",
        "train_bottleneck_generator = train_generator.flow_from_dataframe(\n",
        "    dataframe=image_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode=None,  # No labels needed for feature extraction\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,    # Important to keep order for later matching with labels\n",
        "    subset='training',\n",
        "    workers=os.cpu_count(),\n",
        "    use_multiprocessing=True\n",
        ")\n",
        "# Use base_model to get features before the custom top layers\n",
        "bottleneck_features_train = base_model.predict(train_bottleneck_generator, steps=len(train_bottleneck_generator), verbose=1)\n",
        "np.save(open('bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
        "print(f\"Shape of bottleneck_features_train: {bottleneck_features_train.shape}\")\n",
        "print(\"Bottleneck features for training data saved to bottleneck_features_train.npy\")\n",
        "\n",
        "\n",
        "# 2. Generate bottleneck features for the validation data\n",
        "print(\"\\nGenerating bottleneck features for validation data...\")\n",
        "validation_bottleneck_generator = train_generator.flow_from_dataframe(\n",
        "    dataframe=image_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode=None,  # No labels needed for feature extraction\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,    # Important to keep order\n",
        "    subset='validation',\n",
        "    workers=os.cpu_count(),\n",
        "    use_multiprocessing=True\n",
        ")\n",
        "# Use base_model to get features before the custom top layers\n",
        "bottleneck_features_validation = base_model.predict(validation_bottleneck_generator, steps=len(validation_bottleneck_generator), verbose=1)\n",
        "np.save(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)\n",
        "print(f\"Shape of bottleneck_features_validation: {bottleneck_features_validation.shape}\")\n",
        "print(\"Bottleneck features for validation data saved to bottleneck_features_validation.npy\")\n",
        "\n",
        "\n",
        "# 3. Generate bottleneck features for the test data\n",
        "print(\"\\nGenerating bottleneck features for test data...\")\n",
        "test_bottleneck_generator = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_image_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode=None, # No labels needed\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    workers=os.cpu_count(),\n",
        "    use_multiprocessing=True\n",
        ")\n",
        "# Use base_model to get features before the custom top layers\n",
        "bottleneck_features_test = base_model.predict(test_bottleneck_generator, steps=len(test_bottleneck_generator), verbose=1)\n",
        "np.save(open('bottleneck_features_test.npy', 'wb'), bottleneck_features_test)\n",
        "print(f\"Shape of bottleneck_features_test: {bottleneck_features_test.shape}\")\n",
        "print(\"Bottleneck features for test data saved to bottleneck_features_test.npy\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating bottleneck features for training data...\n",
            "Found 6404 validated image filenames.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 440ms/step\n",
            "Shape of bottleneck_features_train: (6404, 7, 7, 512)\n",
            "Bottleneck features for training data saved to bottleneck_features_train.npy\n",
            "\n",
            "Generating bottleneck features for validation data...\n",
            "Found 1601 validated image filenames.\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 409ms/step\n",
            "Shape of bottleneck_features_validation: (1601, 7, 7, 512)\n",
            "Bottleneck features for validation data saved to bottleneck_features_validation.npy\n",
            "\n",
            "Generating bottleneck features for test data...\n",
            "Found 2023 validated image filenames.\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 173ms/step\n",
            "Shape of bottleneck_features_test: (2023, 7, 7, 512)\n",
            "Bottleneck features for test data saved to bottleneck_features_test.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87a68e10",
        "outputId": "9b682ae9-13b6-44d9-d337-4735b5b123ca"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "# Assuming base_model (VGG16 without top) is already defined from cell Ujz8DEgJBwwf or CpuXeXF9DsE1\n",
        "# Assuming train_generator and test_generator are defined from cell P3KTP5lgautI\n",
        "# Assuming image_df and test_image_df are populated from cell c304ff87 or c304ff87\n",
        "\n",
        "batch_size = 32 # Define batch_size\n",
        "\n",
        "# 1. Generate bottleneck features for the training data\n",
        "print(\"Generating bottleneck features for training data...\")\n",
        "train_bottleneck_generator = train_generator.flow_from_dataframe(\n",
        "    dataframe=image_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode=None,  # No labels needed for feature extraction\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,    # Important to keep order for later matching with labels\n",
        "    subset='training',\n",
        "    workers=os.cpu_count(),\n",
        "    use_multiprocessing=True\n",
        ")\n",
        "# Use base_model to get features before the custom top layers\n",
        "bottleneck_features_train = base_model.predict(train_bottleneck_generator, steps=len(train_bottleneck_generator), verbose=1)\n",
        "np.save(open('bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
        "print(f\"Shape of bottleneck_features_train: {bottleneck_features_train.shape}\")\n",
        "print(\"Bottleneck features for training data saved to bottleneck_features_train.npy\")\n",
        "\n",
        "\n",
        "# 2. Generate bottleneck features for the validation data\n",
        "print(\"\\nGenerating bottleneck features for validation data...\")\n",
        "validation_bottleneck_generator = train_generator.flow_from_dataframe(\n",
        "    dataframe=image_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode=None,  # No labels needed for feature extraction\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,    # Important to keep order\n",
        "    subset='validation',\n",
        "    workers=os.cpu_count(),\n",
        "    use_multiprocessing=True\n",
        ")\n",
        "# Use base_model to get features before the custom top layers\n",
        "bottleneck_features_validation = base_model.predict(validation_bottleneck_generator, steps=len(validation_bottleneck_generator), verbose=1)\n",
        "np.save(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)\n",
        "print(f\"Shape of bottleneck_features_validation: {bottleneck_features_validation.shape}\")\n",
        "print(\"Bottleneck features for validation data saved to bottleneck_features_validation.npy\")\n",
        "\n",
        "\n",
        "# 3. Generate bottleneck features for the test data\n",
        "print(\"\\nGenerating bottleneck features for test data...\")\n",
        "test_bottleneck_generator = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_image_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode=None, # No labels needed\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    workers=os.cpu_count(),\n",
        "    use_multiprocessing=True\n",
        ")\n",
        "# Use base_model to get features before the custom top layers\n",
        "bottleneck_features_test = base_model.predict(test_bottleneck_generator, steps=len(test_bottleneck_generator), verbose=1)\n",
        "np.save(open('bottleneck_features_test.npy', 'wb'), bottleneck_features_test)\n",
        "print(f\"Shape of bottleneck_features_test: {bottleneck_features_test.shape}\")\n",
        "print(\"Bottleneck features for test data saved to bottleneck_features_test.npy\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating bottleneck features for training data...\n",
            "Found 6404 validated image filenames.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m201/201\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 435ms/step\n",
            "Shape of bottleneck_features_train: (6404, 7, 7, 512)\n",
            "Bottleneck features for training data saved to bottleneck_features_train.npy\n",
            "\n",
            "Generating bottleneck features for validation data...\n",
            "Found 1601 validated image filenames.\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 437ms/step\n",
            "Shape of bottleneck_features_validation: (1601, 7, 7, 512)\n",
            "Bottleneck features for validation data saved to bottleneck_features_validation.npy\n",
            "\n",
            "Generating bottleneck features for test data...\n",
            "Found 2023 validated image filenames.\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 175ms/step\n",
            "Shape of bottleneck_features_test: (2023, 7, 7, 512)\n",
            "Bottleneck features for test data saved to bottleneck_features_test.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import optimizers\n",
        "import numpy as np\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# 2. BUILD THE TOP MODEL (The Classifier)\n",
        "# This model will be trained to recognize Cats vs Dogs\n",
        "top_model = Sequential([\n",
        "    Flatten(input_shape=base_model.output_shape[1:]),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(2, activation='softmax') # 2 classes: Cats and Dogs\n",
        "])\n",
        "full_input = Input(shape=(224, 224, 3))\n",
        "x = base_model(full_input)\n",
        "full_output = top_model(x)\n",
        "model = Model(inputs=full_input, outputs=full_output)\n",
        "\n",
        "# 4. FREEZE VGG16 LAYERS\n",
        "# We don't want to ruin the pre-trained VGG16 weights during initial training\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 5. COMPILE\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 6. FIX THE NUMPY'np.save('bottleneck_features_train.npy', bottleneck_features_train)\n",
        "\n",
        "\n",
        "print(\"Model is ready for training. The architecture mismatch is resolved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iVfihjsIgDq",
        "outputId": "84b034bd-b8b9-4fab-ebeb-d8beb3e4f533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is ready for training. The architecture mismatch is resolved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(model, 'model_weights.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ84kRo5IyXU",
        "outputId": "76a53760-db81-445a-ac38-c9a4c060efa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_weights.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e45cf4f",
        "outputId": "f1705da4-7a00-412b-e93c-d6feb8eac740"
      },
      "source": [
        "results=model.evaluate(test_images)\n",
        "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
        "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - accuracy: 0.3845 - loss: 0.7898\n",
            "    Test Loss: 0.74951\n",
            "Test Accuracy: 44.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b39686f",
        "outputId": "1aa53e29-e209-461d-cee1-6da1c881ad50"
      },
      "source": [
        "history = model.fit(\n",
        "    train_images,\n",
        "    steps_per_epoch=len(train_images),\n",
        "    epochs=10,\n",
        "    validation_data=val_images,\n",
        "    validation_steps=len(val_images)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 894ms/step - accuracy: 0.6936 - loss: 0.6917 - val_accuracy: 0.8687 - val_loss: 0.3009\n",
            "Epoch 2/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 878ms/step - accuracy: 0.8500 - loss: 0.3337 - val_accuracy: 0.8822 - val_loss: 0.2603\n",
            "Epoch 3/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 872ms/step - accuracy: 0.8780 - loss: 0.2871 - val_accuracy: 0.9139 - val_loss: 0.2129\n",
            "Epoch 4/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 869ms/step - accuracy: 0.8895 - loss: 0.2639 - val_accuracy: 0.9154 - val_loss: 0.2007\n",
            "Epoch 5/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 874ms/step - accuracy: 0.8900 - loss: 0.2557 - val_accuracy: 0.9151 - val_loss: 0.1993\n",
            "Epoch 6/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 876ms/step - accuracy: 0.8961 - loss: 0.2481 - val_accuracy: 0.9137 - val_loss: 0.2044\n",
            "Epoch 7/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 1s/step - accuracy: 0.8988 - loss: 0.2416 - val_accuracy: 0.8914 - val_loss: 0.2432\n",
            "Epoch 8/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 865ms/step - accuracy: 0.9002 - loss: 0.2235 - val_accuracy: 0.8977 - val_loss: 0.2387\n",
            "Epoch 9/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 871ms/step - accuracy: 0.9049 - loss: 0.2285 - val_accuracy: 0.9245 - val_loss: 0.1807\n",
            "Epoch 10/10\n",
            "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 901ms/step - accuracy: 0.9087 - loss: 0.2169 - val_accuracy: 0.9009 - val_loss: 0.2337\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results=model.evaluate(test_images)\n",
        "print(\"    Test Loss: {:.5f}\".format(results[0]))\n",
        "print(\"Test Accuracy: {:.2f}%\".format(results[1] * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F1eym7dPkGd",
        "outputId": "0cd265a4-34ac-434e-d3dc-fc6a27a75f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 178ms/step - accuracy: 0.8811 - loss: 0.2692\n",
            "    Test Loss: 0.19819\n",
            "Test Accuracy: 92.04%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "pickle.dump(Conv2D, open('conv2d.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "GuFNknedlu07"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ua0J2-RLnVOf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}